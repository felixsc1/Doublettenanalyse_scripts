{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helper_functions.file_io_functions import detect_raw_files, load_processed_data, create_excel_file_from_dict\n",
    "from helper_functions.cleanup_functions import raw_cleanup\n",
    "from helper_functions.edges_clusters import find_name_adresse_doubletten\n",
    "from helper_functions.filter_muster_organisationen import general_exclusion_criteria_personen, find_portal_vs_physisch_doublette, find_email_doubletten\n",
    "from helper_functions.filter_muster_personen import filter_personen_connected_to_same_organisation, split_groups_mitarbeiter_admnistrator\n",
    "from helper_functions.analyses_formatting import final_touch_batch, final_touch\n",
    "\n",
    "# This extension will cause imported modules to be reloaded if there were changes made.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Disable some annoying warnings. \n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Set the global number formatting\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data & Basic Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check if all required Expertensuche files exist.\n",
    "raw_files, error_message = detect_raw_files(\"../GraphViewerApp/data/\")\n",
    "if error_message:\n",
    "    print(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading excel files and extracting hyperlinks (takes several minutes)...\n",
      "Basic cleanup Organisationen & Personen...\n",
      "Aggregating additional Expertensuchen...\n",
      "Storing dataframes as pickle...\n",
      "Reading excel files and extracting hyperlinks (takes several minutes)...\n",
      "Basic cleanup Organisationen & Personen...\n",
      "Aggregating additional Expertensuchen...\n",
      "Storing dataframes as pickle...\n"
     ]
    }
   ],
   "source": [
    "# Needs to be run only once, does processing for personen_ and organisationen_ analyses. Processed data can then be loaded from cell below this.\n",
    "\n",
    "df_organisationen, df_personen = raw_cleanup(raw_files, skip_hyperlink_step=True)  # Takes >5 min\n",
    "_, df_personen_inkl_sonstiges = raw_cleanup(raw_files, remove_personen_Sonstiges=False, skip_hyperlink_step=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally, skip above processing and load cleaned data\n",
    "\n",
    "Uncomment lines below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dfs = load_processed_data() #standard\n",
    "# data_dfs_sonstiges = load_processed_data(file_path=\"data/calculated/personen_organisationen_dfs_processed_with_sonstiges_personen.pickle\")\n",
    "\n",
    "df_personen = data_dfs[\"personen\"]\n",
    "df_organisationsrollen = data_dfs[\"organisationsrollen\"] # ! Its called organisationsrollen historically, but contains Produkt infos for Personen as well!\n",
    "# df_organisationen = data_dfs[\"organisationen\"]\n",
    "\n",
    "# df_personen_inkl_sonstiges = data_dfs_sonstiges[\"personen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find and filter Doubletten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All potential doubletten (same Name + Address)\n",
    "# personen_doubletten = find_name_adresse_doubletten(df_personen, organisationen=False)\n",
    "\n",
    "# Alternative: Use abbreviated first names for matching.\n",
    "personen_doubletten = find_name_adresse_doubletten(df_personen, organisationen=False, abbreviated_first_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Some general exclusion criteria: ------\n",
    "# The resulting dataframe contains Personen connected to the same Organisation, that may have the following attributes:\n",
    "\n",
    "no_Produkte = False\n",
    "no_Geschaeftspartner = False\n",
    "no_Servicerole = False\n",
    "\n",
    "only_physisch = False\n",
    "only_mitarbeiter = False  # No \"Administrator\" roles\n",
    "\n",
    "\n",
    "personen_doubletten_filtered = general_exclusion_criteria_personen(personen_doubletten, no_Produkte=no_Produkte, no_Geschaeftspartner=no_Geschaeftspartner, no_Servicerole=no_Servicerole, only_physisch=only_physisch, only_mitarbeiter=only_mitarbeiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muster: Doublette Physisch\n",
    "\n",
    "Alle Doubletten haben Versandart Physisch, sind mit derselben Organisation verknüpft. \n",
    "\n",
    "Keine Geschäftspartner. Keine Servicerollen. Aber können Produkte haben (Personenrolle und ProduktID werden dann angezeigt).\n",
    "\n",
    "Separates sheet für folgende Fälle: 2+ Mitarbeiter, 1 Administrator und 1+ Mitarbeiter, oder 2+ Administrator (plus Mitarbeiter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "personen_doubletten_filtered = general_exclusion_criteria_personen(personen_doubletten, no_Produkte=False, no_Geschaeftspartner=True, no_Servicerole=True, only_physisch=True, only_mitarbeiter=False)\n",
    "\n",
    "# Starting point for most analyses: Only consider groups where all members are connected to same organisation.\n",
    "doubletten_same_org = filter_personen_connected_to_same_organisation(personen_doubletten_filtered, df_organisationen)\n",
    "\n",
    "doublette_physisch_dict = split_groups_mitarbeiter_admnistrator(doubletten_same_org)\n",
    "\n",
    "cols_to_keep = [\"ReferenceID\", \"Name_original\", \"Objekt_link\", \"address_full\", \"Versandart\", \"EMailAdresse\", \"VerknuepftesObjekt\", \"Verknuepfungsart\", \"VerknuepftesObjektID\", \"Produkt_rolle\", \"Produkt_RefID\", \"cluster_id\", \"score_details\", \"score\", \"master\"]\n",
    "doublette_physisch_dict_formatted = final_touch_batch(doublette_physisch_dict, cols_to_keep=cols_to_keep, alphanumeric=True)\n",
    "\n",
    "create_excel_file_from_dict(doublette_physisch_dict_formatted, output_file=\"output/Personendoubletten_physisch.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muster: Doublette Portal\n",
    "\n",
    "Identisch zu Doublette Physisch, aber mindestens eine der Doubletten hat Versandart Portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "personen_doubletten_filtered = general_exclusion_criteria_personen(personen_doubletten, no_Produkte=False, no_Geschaeftspartner=True, no_Servicerole=True, only_physisch=False, only_mitarbeiter=False)\n",
    "doubletten_same_org = filter_personen_connected_to_same_organisation(personen_doubletten_filtered, df_organisationen)\n",
    "\n",
    "# Filter groups where at least one member has Versandart Portal.\n",
    "doubletten_same_org = doubletten_same_org.groupby('cluster_id').filter(lambda x: (x['Versandart'] == 'Portal').any())\n",
    "\n",
    "doublette_portal_dict = split_groups_mitarbeiter_admnistrator(doubletten_same_org)\n",
    "\n",
    "cols_to_keep = [\"ReferenceID\", \"Name_original\", \"Objekt_link\", \"address_full\", \"Versandart\", \"EMailAdresse\", \"VerknuepftesObjekt\", \"Verknuepfungsart\", \"VerknuepftesObjektID\", \"Produkt_rolle\", \"Produkt_RefID\", \"cluster_id\", \"score_details\", \"score\", \"master\"]\n",
    "doublette_portal_dict_formatted = final_touch_batch(doublette_portal_dict, cols_to_keep=cols_to_keep, alphanumeric=True)\n",
    "\n",
    "create_excel_file_from_dict(doublette_portal_dict_formatted, output_file=\"output/Personendoubletten_portal.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doubletten Physisch und Portal\n",
    "\n",
    "Alle Doubletten mit selbem Name, Adresse und Email (zwei Varianten, exakter match, oder leere email erlauben), unabhängig von Verknüpfungen zu Organisationen.\n",
    "Mindestens eine Doublette hat Versandart Portal und eine Versandart Physisch.\n",
    "\n",
    "Können Servicerollen und Produkte haben und bei Geschäftspartnern vorkommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "personen_physisch_vs_portal_only_nonempty_email = find_portal_vs_physisch_doublette(df_personen, strict_email=True)\n",
    "personen_physisch_vs_portal_empty_email = find_portal_vs_physisch_doublette(df_personen, strict_email=False)\n",
    "\n",
    "cols_to_keep = [\"ReferenceID\", \"Name_original\", \"Objekt_link\", \"address_full\", \"Versandart\", \"EMailAdresse\", \"VerknuepftesObjekt\", \"Verknuepfungsart\", \"VerknuepftesObjektID\", \"Produkt_rolle\", \"Produkt_RefID\", \"Geschaeftspartner\", \"Servicerole_string\", \"cluster_id\", \"score_details\", \"score\", \"master\"]\n",
    "\n",
    "personen_physisch_vs_portal_only_nonempty_email = final_touch(personen_physisch_vs_portal_only_nonempty_email, cols_to_keep)\n",
    "personen_physisch_vs_portal_empty_email = final_touch(personen_physisch_vs_portal_empty_email, cols_to_keep)\n",
    "\n",
    "with pd.ExcelWriter('output/Personen_Portal_Vs_Physisch.xlsx', engine='openpyxl') as writer:\n",
    "    personen_physisch_vs_portal_only_nonempty_email.to_excel(writer, sheet_name='nonempty_email_only', index=False)\n",
    "    personen_physisch_vs_portal_empty_email.to_excel(writer, sheet_name='empty_email_allowed', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doubletten Portal - Email\n",
    "\n",
    "Alle Doubletten mit selber Email (unabhängig von Name und Addressen), mindestens eine Doublette hat Versandart Portal.\n",
    "\n",
    "Können Servicerollen und Produkte haben und bei Geschäftspartnern vorkommen.\n",
    "\n",
    "Erweiterungen:\n",
    "\n",
    "- UVEK liste enthält auch Personen mit Verknüpfungsart Sonstiges. Sind in separaten files inkludiert.\n",
    "\n",
    "- Physisch email doubletten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "personen_email_portal = find_email_doubletten(df_personen, portal=True)\n",
    "# personen_email_pyhsisch = find_email_doubletten(df_personen, portal=False)\n",
    "personen_email_portal_sonstiges = find_email_doubletten(df_personen_inkl_sonstiges, portal=True)\n",
    "personen_email_pyhsisch_sonstiges = find_email_doubletten(df_personen_inkl_sonstiges, portal=False)\n",
    "\n",
    "cols_to_keep = [\"ReferenceID\", \"Name_original\", \"Objekt_link\", \"address_full\", \"Versandart\", \"EMailAdresse\", \"VerknuepftesObjekt\", \"Verknuepfungsart\", \"VerknuepftesObjektID\", \"Produkt_rolle\", \"Produkt_RefID\", \"Geschaeftspartner\", \"Servicerole_string\", \"cluster_id\", \"score_details\", \"score\", \"master\"]\n",
    "personen_email_portal = final_touch(personen_email_portal, cols_to_keep)\n",
    "personen_email_physisch_sonstiges = final_touch(personen_email_pyhsisch_sonstiges, cols_to_keep)\n",
    "personen_email_portal_sonstiges = final_touch(personen_email_portal_sonstiges, cols_to_keep)\n",
    "\n",
    "personen_email_portal.to_excel(\"output/Personen_Email_Portal.xlsx\", index=False)\n",
    "personen_email_physisch_sonstiges.to_excel(\"output/Personen_Email_Physisch_inkl_VerknuepfungsartSonstiges.xlsx\", index=False)\n",
    "personen_email_portal_sonstiges.to_excel(\"output/Personen_Email_Portal_inkl_VerknuepfungsartSonstiges.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbreviated first names: Statistics about how much it would change clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 additional Doubletten with same name and address (NOT necessarily to same organisation)\n",
      "29 additional Doubletten with same name and address AND same organisation\n"
     ]
    }
   ],
   "source": [
    "personen_doubletten = find_name_adresse_doubletten(df_personen, organisationen=False)\n",
    "personen_doubletten_abbrev = find_name_adresse_doubletten(df_personen, organisationen=False, abbreviated_first_name=True)\n",
    "\n",
    "# Lets consider any doubletten with same name and address, but irrespective of whether they have Produkte, Geschäftspartner, etc.\n",
    "df1 = general_exclusion_criteria_personen(personen_doubletten, no_Produkte=False, no_Geschaeftspartner=False, no_Servicerole=False, only_physisch=False, only_mitarbeiter=False)\n",
    "df2 = general_exclusion_criteria_personen(personen_doubletten_abbrev, no_Produkte=False, no_Geschaeftspartner=False, no_Servicerole=False, only_physisch=False, only_mitarbeiter=False)\n",
    "\n",
    "print(f'{len(df2) - len(df1)} additional Doubletten with same name and address (NOT necessarily to same organisation)')\n",
    "\n",
    "df1a = filter_personen_connected_to_same_organisation(df1, df_organisationen)\n",
    "df2a = filter_personen_connected_to_same_organisation(df2, df_organisationen)\n",
    "\n",
    "print(f'{len(df2a) - len(df1a)} additional Doubletten with same name and address AND same organisation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New unique names created by abbreviation:\n",
      "29: {'annalise gross', 'erich geissmann', 'sydney weill', 'tom battaglia', 'raphael boullet', 'melvin belli', 'steve christe', 'rémi sebag', 'a. blaser', 'mickäel prince', 'rene schiefer', 'nicole fischli', 'mickaël prince', 'giusi raffa', 'melwin belli', 'maurico ernst', 'remi sebag', 'sidney weill', 'giuseppe raffa', 'walther knecht', 'anneliese gross', 'stève christe', 'e. geissmann', 'walter knecht', 'raphae boullet', 'nicole-fabienne fischli', 'rené schiefer', 'thomas battaglia', 'mauricio ernst'}\n"
     ]
    }
   ],
   "source": [
    "# Get unique names before and after abbreviation\n",
    "unique_original = set(df1a['Name'].unique())\n",
    "unique_abbreviated = set(df2a['Name'].unique())\n",
    "\n",
    "# Determine new unique names in the abbreviated column that were not in the original\n",
    "new_unique_names = unique_abbreviated - unique_original\n",
    "\n",
    "# Display the new unique names\n",
    "print(\"New unique names created by abbreviation:\")\n",
    "print(f\"{len(new_unique_names)}: {new_unique_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files are identical.\n"
     ]
    }
   ],
   "source": [
    "# Quick check to see if two excel files are the same:\n",
    "\n",
    "# Load the Excel files\n",
    "df1 = pd.read_excel('C:\\\\GitRepos\\\\Doublettenanalyse_scripts\\\\output\\\\Personen\\\\Personen_Portal_Vs_Physisch.xlsx')\n",
    "df2 = pd.read_excel('C:\\\\GitRepos\\\\Doublettenanalyse_scripts\\\\output\\\\Personen_Portal_Vs_Physisch.xlsx')\n",
    "\n",
    "# Check if both DataFrames are identical\n",
    "if df1.equals(df2):\n",
    "    print(\"The files are identical.\")\n",
    "else:\n",
    "    print(\"The files are different.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
